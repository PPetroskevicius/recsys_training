{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 6: Model-based Collaborative Filtering for **Ranking** Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we still do Collaborative Filtering and Matrix Factorization in this unit, we do something fundamentally different: we change from rating prediction to **ranking prediction**.\n",
    "\n",
    "We achieve this by changing the optimization criterion. Instead of minimizing the deviation between true and predicted ratings we push positive and negative user-item combinationa as much as possible apart. We transform explicit user feedback into implicit feedback. Implicit feedback refers to user interaction without the purpose to reflect preference or disregard and is much more common in pactice. Ranking prediction algorithms tackle to learn from implicit feedback data.\n",
    "\n",
    "In addition, ranking-based algorithms yield a much more intuitive prediction result. Our goal is to present to the user a very limited amount of items in the correct ordering. Therefore, ordering is much more important than rating prediction. Ranking-based algorithms like BPR work pair-wise, i.e. for a user and two items they yield the correct order of both items for the user. Generalizing from this, we can impose an ordering on our item corpus and pick the top-$N$ to present to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import itertools\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recsys_training.data import Dataset\n",
    "from recsys_training.evaluation import get_relevant_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml100k_ratings_filepath = '../data/raw/ml-100k/u.data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different to previous units, we work with implicit feedback data now. However, MovieLens is an explicit feedback dataset, we can argue that everything above the user mean ratings is positive and everything below is negative. Bayesian Personalized Ranking learns from implicit positive feedback data and randomly samples negative feedback data during training. Thus, we keep all ratings above a threhold of $4.0$ and remove all other ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(ml100k_ratings_filepath)\n",
    "data.filter(min_rating=4.0)\n",
    "data.rating_split(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we want to learn the user/item latent factors from rating data, we first randomly initialize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "m = data.n_users\n",
    "n = data.n_items\n",
    "d = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Factor initialization\n",
    "random_state = np.random.RandomState(seed)\n",
    "user_factors = (random_state.rand(m, d) - 0.5) / d\n",
    "item_factors = (random_state.rand(n, d) - 0.5) / d\n",
    "        \n",
    "ratings = data.train_ratings.sample(frac=1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive implicit feedback items\n",
    "user_pos_items = dict()\n",
    "# corpus of all remaining items for every user\n",
    "# Ask me about the \"Non missing at random hypothesis\" ;)\n",
    "user_neg_items = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = ratings[['user', 'item']].groupby('user')\n",
    "groups = grouped.groups.keys()\n",
    "for user in data.users:\n",
    "    pos_items = []\n",
    "    if user in groups:\n",
    "        pos_items = grouped.get_group(user).item.values\n",
    "    neg_items = np.setdiff1d(data.items, pos_items)\n",
    "    user_pos_items[user] = pos_items\n",
    "    user_neg_items[user] = neg_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, there is some math involved:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{x}_{uij} = \\hat{x}_{ui} - \\hat{x}_{uj} \\\\\n",
    "x_{ui} = \\sum_{f=1}^{d} w_{uf} \\cdot h_{if}, i \\in I_u^+ \\\\\n",
    "x_{uj} = \\sum_{f=1}^{d} w_{uf} \\cdot h_{jf}, j \\in I_u^- \\\\\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{BPR-Opt} := \\sum_{(u,i,j) \\in D_S} \\ln\\sigma(\\hat{x}_{uijj}) - \\lambda_{\\Theta} \\cdot ||\\Theta||^2\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial \\text{BPR-Opt}}{\\partial \\Theta} = \\frac{-e^{-\\hat{x}_{uij}}}{1+e^{-\\hat{x}_{uij}}} \\cdot \\frac{\\partial \\hat{x}_{uij}}{\\partial \\Theta} - \\lambda_{\\Theta} \\cdot \\Theta\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial x_{uij}}{\\partial \\Theta} =\n",
    "\\begin{cases}\n",
    "(h_{if}-h_{jf}) & \\text{for } \\Theta = w_{uf} \\\\\n",
    "w_{uf} & \\text{for } \\Theta = h_{if} \\\\\n",
    "-w_{uf} & \\text{for } \\Theta = h_{jf}\n",
    "\\end{cases}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about regularization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sampling(user: int, user_neg_items: Dict[int, np.array]) -> int:\n",
    "    \"\"\"\n",
    "    Return the item ids for negative samples\n",
    "    \"\"\"\n",
    "    negative_item = np.random.choice(user_neg_items[user])\n",
    "    \n",
    "    return negative_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Parrot.png)\n",
    "\n",
    "**Task:** Adapt the `compute_gradients` method from the unit before to realize stochastic gradient descent (SGD) for Bayesian Personalized Ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(user_embed: np.array,\n",
    "                      pos_item_embed: np.array,\n",
    "                      neg_item_embed: np.array,\n",
    "                      l2_decay: Dict[str, float]) -> Tuple[np.array, np.array, np.array]:\n",
    "    \n",
    "    pos_pred = np.sum(user_embed * pos_item_embed)\n",
    "    neg_pred = np.sum(user_embed * neg_item_embed)\n",
    "    pred = pos_pred - neg_pred\n",
    "\n",
    "    generic_grad = None\n",
    "    \n",
    "    # Gradients\n",
    "    user_grad = None\n",
    "    pos_item_grad = None\n",
    "    neg_item_grad = None\n",
    "    \n",
    "    # Add L2-Decay\n",
    "    user_grad += None\n",
    "    pos_item_grad += None\n",
    "    neg_item_grad += None\n",
    "\n",
    "    return user_grad, pos_item_grad, neg_item_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_update(epoch: int, samples: np.array) -> float:\n",
    "    # take the 1000 most recent ratings and compute the mean ranking loss\n",
    "    users = samples[:, 0]\n",
    "    pos_items = samples[:, 1]\n",
    "    neg_items = np.array([negative_sampling(user, user_neg_items)\n",
    "                          for user in users])\n",
    "\n",
    "    user_embeds = user_factors[users - 1]\n",
    "    pos_item_embeds = item_factors[pos_items - 1]\n",
    "    neg_item_embeds = item_factors[neg_items - 1]\n",
    "\n",
    "    pos_preds = np.sum(user_embeds * pos_item_embeds, axis=1)\n",
    "    neg_preds = np.sum(user_embeds * neg_item_embeds, axis=1)\n",
    "    preds = pos_preds - neg_preds\n",
    "\n",
    "    loss = -np.log(sigmoid(preds)).mean()\n",
    "    print(f\"Epoch {epoch+1:02d}: Mean Ranking Loss: {loss:.4f}\")\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of minibatch gradient descent we do **stochastic gradient descent** (SGD) here. It just shrinks the batch size down to 1 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "learning_rate = 0.05\n",
    "l2_decay = {'user': 0.002, 'pos': 0.0, 'neg': 0.002}\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_arr = ratings[['user', 'item']].values\n",
    "n_ratings = len(ratings_arr)\n",
    "loss_trace = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for _ in range(len(ratings)):\n",
    "        random_index = np.random.randint(n_ratings)\n",
    "        user, pos_item = tuple(ratings_arr[random_index])\n",
    "        neg_item = negative_sampling(user, user_neg_items)\n",
    "\n",
    "        # Deduct 1 as user ids are 1-indexed, but array is 0-indexed\n",
    "        user_embed = user_factors[user - 1]\n",
    "        pos_item_embed = item_factors[pos_item - 1]\n",
    "        neg_item_embed = item_factors[neg_item - 1]\n",
    "\n",
    "        user_grad, pos_item_grad, neg_item_grad = \\\n",
    "            compute_gradients(user_embed,\n",
    "                              pos_item_embed,\n",
    "                              neg_item_embed,\n",
    "                              l2_decay)\n",
    "\n",
    "        user_factors[user - 1] -= learning_rate * user_grad\n",
    "        item_factors[pos_item - 1] -= learning_rate * pos_item_grad\n",
    "        item_factors[neg_item - 1] -= learning_rate * neg_item_grad\n",
    "\n",
    "    if verbose:\n",
    "        samples = ratings_arr[-1000:]\n",
    "        loss = print_update(epoch, samples)\n",
    "        loss_trace.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(range(epochs), train_loss_trace, 'b--', label='Train')\n",
    "plt.plot(range(epochs), test_loss_trace, 'g--', label='Test')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the model for Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now created a model to describe users and items in terms of latent vectors. But this time we fitted them to get the rankings correctly. So for obtaining recommendations we simply multiply user-item latent vectors we are interested in and achieve an estimate that can be used to order items for a given user. This time it is not a rating prediction, but still a prediction.\n",
    "\n",
    "For that, we can reuse the `get_prediction` method from previous units.\n",
    "\n",
    "Thus, before writing the `get_recommendations` again we first implement `get_prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(user: int, items: np.array = None, remove_known_pos: bool = True) -> Dict[int, Dict[str, float]]:\n",
    "    if items is None:\n",
    "        if remove_known_pos:\n",
    "            # Predict from unobserved items\n",
    "            # We simplified this compared to the unit before\n",
    "            items = user_neg_items[user]\n",
    "        else:\n",
    "            items = np.array(data.items)\n",
    "    if type(items) == np.int64:\n",
    "        items = np.array([items])\n",
    "    \n",
    "    user_embed = user_factors[user - 1].reshape(1, -1)\n",
    "    item_embeds = item_factors[items - 1].reshape(len(items), -1)\n",
    "\n",
    "    # use array-broadcasting\n",
    "    preds = np.sum(user_embed * item_embeds, axis=1)\n",
    "    sorting = np.argsort(preds)[::-1]\n",
    "    preds = {item: {'pred': pred} for item, pred in\n",
    "             zip(items[sorting], preds[sorting])}\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_predictions = get_prediction(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(item_predictions.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user: int, N: int, remove_known_pos: bool = False) -> List[Tuple[int, Dict[str, float]]]:\n",
    "    predictions = get_prediction(user, remove_known_pos=remove_known_pos)\n",
    "    recommendations = []\n",
    "    for item, pred in predictions.items():\n",
    "        add_item = (item, pred)\n",
    "        recommendations.append(add_item)\n",
    "        if len(recommendations) == N:\n",
    "            break\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = get_recommendations(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_items = get_relevant_items(data.test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = relevant_items.keys()\n",
    "prec_at_N = dict.fromkeys(data.users)\n",
    "\n",
    "for user in users:\n",
    "    recommendations = get_recommendations(user, N, remove_known_pos=True)\n",
    "    recommendations = [val[0] for val in recommendations]\n",
    "    hits = np.intersect1d(recommendations,\n",
    "                          relevant_items[user])\n",
    "    prec_at_N[user] = len(hits)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([val for val in prec_at_N.values() if val is not None])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
