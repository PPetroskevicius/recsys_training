{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 8: Hybrid Recommender Model using both Collaborative Filtering and Content-based Filtering using a Factorization Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we combine CF and CBF.\n",
    "\n",
    "Therefore, we simply add the one-hot-encoded user and item IDs to the data. Thus, the model is capable of factorizing the similarities in rating and features for rating prediction. This combination is called hybrid as it combines two recommenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import itertools\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyfm import pylibfm\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recsys_training.data import Dataset, genres\n",
    "from recsys_training.evaluation import get_relevant_items\n",
    "from recsys_training.utils import get_sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml100k_ratings_filepath = '../data/raw/ml-100k/u.data'\n",
    "ml100k_item_filepath = '../data/raw/ml-100k/u.item'\n",
    "ml100k_user_filepath = '../data/raw/ml-100k/u.user'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(ml100k_ratings_filepath)\n",
    "data.rating_split(seed=42)\n",
    "user_ratings = data.get_user_ratings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_feat = pd.read_csv(ml100k_item_filepath, sep='|', header=None,\n",
    "                        names=['item', 'title', 'release', 'video_release', 'imdb_url']+genres,\n",
    "                        engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat = pd.read_csv(ml100k_user_filepath, sep='|', header=None,\n",
    "                        names=['user', 'age', 'gender', 'occupation', 'zip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User and Item Content (Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep the following information for items:\n",
    "* release year\n",
    "* genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(val, bounds):\n",
    "    min_max_range = bounds['max']-bounds['min']\n",
    "    return (val-bounds['min'])/min_max_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer the release year\n",
    "idxs = item_feat[item_feat['release'].notnull()].index\n",
    "item_feat.loc[idxs, 'release_year'] = item_feat.loc[idxs, 'release'].str.split('-')\n",
    "item_feat.loc[idxs, 'release_year'] = item_feat.loc[idxs, 'release_year'].apply(lambda val: val[2]).astype(int)\n",
    "\n",
    "# Impute median release year value for the items with missing release year\n",
    "top_year = item_feat.loc[idxs, 'release_year'].astype(int).describe()['50%']\n",
    "idx = item_feat[item_feat['release'].isnull()].index\n",
    "item_feat.loc[idx, 'release_year'] = top_year\n",
    "\n",
    "# Min-max scale the release year\n",
    "item_year_bounds = {'min': item_feat['release_year'].min(),\n",
    "                    'max': item_feat['release_year'].max()}\n",
    "item_feat['release_year'] = item_feat['release_year'].apply(\n",
    "    lambda year: min_max_scale(year, item_year_bounds))\n",
    "\n",
    "# Drop other columns\n",
    "item_feat.drop(['title', 'release', 'video_release', 'imdb_url'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep the following information for users:\n",
    "* age\n",
    "* gender\n",
    "* occupation\n",
    "* zip-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max scale the age\n",
    "user_age_bounds = {'min': user_feat['age'].min(),\n",
    "                   'max': user_feat['age'].max()}\n",
    "user_feat['age'] = user_feat['age'].apply(lambda age: min_max_scale(age, user_age_bounds))\n",
    "\n",
    "# Transform gender characters to numerical values (categories)\n",
    "genders = sorted(user_feat['gender'].unique())\n",
    "user_gender_map = dict(zip(genders, range(len(genders))))\n",
    "user_feat['gender'] = user_feat['gender'].map(user_gender_map)\n",
    "\n",
    "# Transform occupation strings to numerical values (categories)\n",
    "occupations = sorted(user_feat['occupation'].unique())\n",
    "user_occupation_map = dict(zip(occupations, range(len(occupations))))\n",
    "user_feat['occupation'] = user_feat['occupation'].map(user_occupation_map)\n",
    "\n",
    "# Transform the zip codes to categories keeping the first three digits and impute for missing\n",
    "idxs = user_feat[~user_feat['zip'].str.isnumeric()].index\n",
    "user_feat.loc[idxs, 'zip'] = '00000'\n",
    "zip_digits_to_cut = 3\n",
    "user_feat['zip'] = user_feat['zip'].apply(lambda val: int(val) // 10 ** zip_digits_to_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we infer profiles by combining item information with rating data for each user to get features that represent the users' preferred genres and film age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_profiler(group):\n",
    "    genre_dist = group[genres].mean()\n",
    "    year_dist = group['release_year'].describe()[['mean', 'std', '50%']]\n",
    "\n",
    "    return pd.concat((genre_dist, year_dist), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_profiles(ratings: pd.DataFrame,\n",
    "                      item_feat: pd.DataFrame,\n",
    "                      min_rating: float = 4.0) -> pd.DataFrame:\n",
    "    ratings = ratings[ratings.rating >= min_rating]\n",
    "    ratings = ratings[['user', 'item']]\n",
    "    ratings = ratings.merge(item_feat, on='item', how='left')\n",
    "    ratings.drop(['item'], axis=1, inplace=True)\n",
    "\n",
    "    grouped = ratings.groupby('user')\n",
    "    profiles = grouped.apply(user_profiler).reset_index()\n",
    "    profiles.rename(columns={'50%': 'median'}, inplace=True)\n",
    "    \n",
    "    return profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we join the original user information with their profiles' information and one-hot-encode categorical information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = get_user_profiles(data.train_ratings, item_feat)\n",
    "user_feat = user_feat.merge(profiles, on='user', how='left')\n",
    "\n",
    "occupation_1H = pd.get_dummies(user_feat['occupation'], prefix='occupation')\n",
    "zip_1H = pd.get_dummies(user_feat['zip'], prefix='zip')\n",
    "\n",
    "user_feat.drop(['occupation', 'zip', ], axis=1, inplace=True)\n",
    "user_feat = pd.concat([user_feat, occupation_1H, zip_1H], axis=1)\n",
    "\n",
    "user_feat.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the user/item id columns and replace the current dataframe indices with their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat.index = user_feat['user'].values\n",
    "user_feat.drop('user', axis=1, inplace=True)\n",
    "\n",
    "item_feat.index = item_feat['item'].values\n",
    "item_feat.drop('item', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorization Machine for a Hybrid Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Steffen Rendle: Factorization Machines](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)\n",
    "\n",
    "[pyFM - Factorization Machines in Python](https://github.com/coreylynch/pyFM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Feature Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch content information for all observed user-item rating combinations\n",
    "user_cb_feat_train = user_feat.loc[data.train_ratings.user.values].values\n",
    "user_cb_feat_test = user_feat.loc[data.test_ratings.user.values].values\n",
    "item_cb_feat_train = item_feat.loc[data.train_ratings.item.values].values\n",
    "item_cb_feat_test = item_feat.loc[data.test_ratings.item.values].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Parrot.png)\n",
    "\n",
    "**Task:** Implement additional arrays for user and item IDs and adjust the design matrices `X_train` and `X_test` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_ids(ids: np.array, length):\n",
    "    pass\n",
    "    return one_hot_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract 1 to turn 1-base-indexed into 0-base-indexed IDs for 0-base-indexed array\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate user and item content information to form design matrices\n",
    "# and convert to sparse matrix in Compressed Sparse Row (CSR) format\n",
    "X_train = pass\n",
    "X_train = pass\n",
    "X_test = pass\n",
    "X_test = pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparsity of Training Data\n",
    "get_sparsity(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparsity of Test Data\n",
    "get_sparsity(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Target Matrices for Rating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data.train_ratings.rating.values.astype(float)\n",
    "y_test = data.test_ratings.rating.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Factorization Machine for Rating Prediction as Regressor using pyFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50  # number of full stochastic passes through the training data\n",
    "k = 16\n",
    "random_seed = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_hybrid = pylibfm.FM(num_factors=k,\n",
    "                       num_iter=n_epochs,\n",
    "                       verbose=True,\n",
    "                       task=\"regression\",\n",
    "                       initial_learning_rate=0.001,\n",
    "                       learning_rate_schedule=\"optimal\",\n",
    "                       seed=random_seed)\n",
    "fm_hybrid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fm_hybrid.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MSE$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MAE$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(fm: object, user: int, user_feat: pd.DataFrame, item_feat: pd.DataFrame,\n",
    "                   items: np.array = None, remove_known_pos: bool = True) -> Dict[int, Dict[str, float]]:\n",
    "    \n",
    "    if items is None:\n",
    "        if remove_known_pos:\n",
    "            # Predict from unobserved items\n",
    "            known_items = np.array(list(user_ratings[user].keys()))\n",
    "            items = np.setdiff1d(data.items, known_items)\n",
    "        else:\n",
    "            items = np.array(data.items)\n",
    "    if type(items) == np.int64:\n",
    "        items = np.array([items])\n",
    "    \n",
    "    n_items = len(items)\n",
    "    \n",
    "    single_user_cb_feat = user_feat.loc[user].values.reshape(1, -1).repeat(n_items, axis=0)\n",
    "    all_items_cb_feat = item_feat.loc[items].values\n",
    "    \n",
    "    input_data = np.concatenate((single_user_cb_feat, all_items_cb_feat), axis=1)\n",
    "    input_data = sparse.csr_matrix(input_data)\n",
    "    \n",
    "    preds = fm.predict(input_data)\n",
    "    sorting = np.argsort(preds)[::-1]\n",
    "    \n",
    "    preds = {item: {'pred': pred} for item, pred in\n",
    "             zip(items[sorting], preds[sorting])}\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_prediction(fm_hybrid, 1, user_feat, item_feat)\n",
    "list(predictions.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(fm_cb: object,\n",
    "                        user: int,\n",
    "                        N: int,\n",
    "                        user_feat: pd.DataFrame,\n",
    "                        item_feat: pd.DataFrame,\n",
    "                        remove_known_pos: bool = True) -> List[Tuple[int, Dict[str, float]]]:\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    predictions = get_prediction(fm_cb, user, user_feat, item_feat,\n",
    "                                 remove_known_pos=remove_known_pos)\n",
    "\n",
    "    for item, pred in predictions.items():\n",
    "        add_item = (item, pred)\n",
    "        recommendations.append(add_item)\n",
    "        if len(recommendations) == N:\n",
    "            break\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations(fm_hybrid, 1, N=10, user_feat=user_feat, item_feat=item_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_items = get_relevant_items(data.test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = relevant_items.keys()\n",
    "prec_at_N = dict.fromkeys(data.users)\n",
    "\n",
    "for user in users:\n",
    "    recommendations = get_recommendations(fm_hybrid, user, N,\n",
    "                                          user_feat=user_feat, item_feat=item_feat)\n",
    "    recommendations = [val[0] for val in recommendations]\n",
    "    hits = np.intersect1d(recommendations,\n",
    "                          relevant_items[user])\n",
    "    prec_at_N[user] = len(hits)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([val for val in prec_at_N.values() if val is not None])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
